print(paste(columna," no tienen valores nulos"))
}
# CAMPOS RELACIONADOS CON LA PROGRAMACION DEL DEPOSITO C
columna <- "Prog.DepC"
if(any(is.na(OZONO2017$Prog.DepC)))
{
for(i in 1:nrow(OZONO2017))
{
if(is.na(OZONO2017[i,columna]))
{
OZONO2017[i,columna] <- -1
}
}
print(paste(columna," actualizados valores nulos"))
}else
{
print(paste(columna," no tienen valores nulos"))
}
View(OZONO2017)
View(OZONO2017)
OZONO2017[which(OZONO2017$Prog.DepA == -1)]
which(OZONO2017$Prog.DepA == -1)
ProgramaA_index <- which(OZONO2017$Prog.DepA == -1)
OZONO2017[ProgramaA_index]
OZONO2017[ProgramaA_index[1]]
OZONO2017[ProgramaA_index[,1]]
OZONO2017[39850]
OZONO2017[39850,]
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
par(mfrow = c(1,2))
hist(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA,main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
plot(OZONO2017$Ozono.DepA,OZONO2017$Prog.DepA,main = "Dispersion")
abline((OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA),col="yellow")
plot(OZONO2017$Prog.DepA,OZONO2017$Ozono.DepA,main = "Dispersion")
abline((OZONO2017$Prog.DepA~OZONO2017$Ozono.DepA),col="yellow")
plot(OZONO2017$Prog.DepA,OZONO2017$Ozono.DepA,main = "Dispersion")
plot(OZONO2017$Prog.DepA,OZONO2017$Ozono.DepA,main = "Dispersion")
abline((OZONO2017$Prog.DepA~OZONO2017$Ozono.DepA),col="red")
plot(OZONO2017$Prog.DepA,OZONO2017$Redox.DepA,main = "Dispersion")
plot(OZONO2017$Prog.DepA,OZONO2017$Redox.DepA,main = "Dispersion")
abline(lm(OZONO2017$Prog.DepA~OZONO2017$Ozono.DepA),col="red")
plot(OZONO2017$Prog.DepA,OZONO2017$Redox.DepA,main = "Dispersion")
abline(lm(OZONO2017$Prog.DepA~OZONO2017$Redoz.DepA),col="red")
plot(OZONO2017$Prog.DepA,OZONO2017$Redox.DepA,main = "Dispersion")
abline(lm(OZONO2017$Prog.DepA~OZONO2017$Redox.DepA),col="red")
par(mfrow = c(1,2))
hist(OZONO2017$Ozono.DepA,main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
hist(lm(OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
hist(log(OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
par(mfrow = c(1,2))
hist(log10(OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
hist((OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
par(mfrow = c(1,2))
hist((OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
summary(OZONO2017$Prog.DepA)
par(mfrow = c(1,2))
hist((OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
par(mfrow = c(1,2))
hist(OZONO2017$Redox.DepA,main = "REDOX Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Redox.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
par(mfrow = c(1,2))
hist(OZONO2017$Temp.DepA,main = "TEMPERATURA Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Temp.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
summary(OZONO2017$Ozono.DepA)
par(mfrow = c(1,2))
hist((OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
summary(OZONO2017$Prog.DepA)
summary(OZONO2017$Ozono.DepA)
par(mfrow = c(1,2))
hist((OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
summary(OZONO2017$Ozono.DepA)
par(mfrow = c(1,2))
hist((OZONO2017$Ozono.DepA),main = "OZONO Deposito A",xlab = "Deposito A",ylab = "Frecuencias")
boxplot(OZONO2017$Ozono.DepA~OZONO2017$Prog.DepA, horizontal = TRUE)
View(OZONO2017)
getwd()
setwd("C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/bolsas")
getwd()
fenale <- read.table("female.csv")
View(fenale)
# Including needed libraries
library(qdapDictionaries)
library(qdapRegex)
library(qdapTools)
library(RColorBrewer)
library(qdap)
library(XML)
library(NLP)
library(tm)
library(splitstackshape)
library(lattice)
library(ggplot2)
library(caret)
GenerateVocabulary <- function(path, n = 1000, lowcase = TRUE, punctuations = TRUE, numbers = TRUE, whitespaces = TRUE, swlang = "", swlist = "", verbose = TRUE, sex = "",pais = "")
{
setwd(path)
# Reading corpus list of files
files = list.files(pattern="*.xml")
tr = read.table("C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/training/truth.txt", sep=":")
tr = tr[,c(1,4,7)]
colnames(tr) <- c("id","sexo","pais")
tr$id <- as.character(tr$id)
# Reading files contents and concatenating into the corpus.raw variable
corpus.raw <- NULL
i <- 0
for (file in files)
{
# Para generar las palabras por sexo
if(sex!="")
{
file2 <- gsub(".xml","",file)
#print(file)
id_sex <- tr[which(tr$id == file2),2]
if(id_sex == sex)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
}
# Para generar las palabras por pais
if(pais!="")
{
file2 <- gsub(".xml","",file)
#print(file)
id_pais <- tr[which(tr$id == file2),3]
if(id_pais == pais)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
}
}
# Preprocessing the corpus
corpus.preprocessed <- corpus.raw
if (lowcase) {
if (verbose) print("Tolower...")
corpus.preprocessed <- tolower(corpus.preprocessed)
}
if (punctuations) {
if (verbose) print("Removing punctuations...")
corpus.preprocessed <- removePunctuation(corpus.preprocessed)
}
if (numbers) {
if (verbose) print("Removing numbers...")
corpus.preprocessed <- removeNumbers(corpus.preprocessed)
}
if (whitespaces) {
if (verbose) print("Stripping whitestpaces...")
corpus.preprocessed <- stripWhitespace(corpus.preprocessed)
}
if (swlang!="")	{
if (verbose) print(paste("Removing stopwords for language ", swlang , "..."))
corpus.preprocessed <- removeWords(corpus.preprocessed, stopwords(swlang))
}
if (swlist!="") {
if (verbose) print("Removing provided stopwords...")
corpus.preprocessed <- removeWords(corpus.preprocessed, swlist)
}
# Generating the vocabulary as the n most frequent terms
#if (verbose) print("Generating frequency terms")
#corpus.frequentterms <- freq_terms(corpus.preprocessed, n)
#if (verbose) plot(corpus.frequentterms)
#return (corpus.frequentterms)
return (corpus.preprocessed)
}
vocabulary <- GenerateVocabulary(path_training, n, swlang=lang)
start.time <- Sys.time()
# Preparing parameters
n <- 50
lang <- "es"
#path_training <- "/home/algar11@alumno.upv.es/Descargas/pan-ap17-bigdata/training"		# Your training path
#path_test <- "/home/algar11@alumno.upv.es/Descargas/pan-ap17-bigdata/test"							# Your test path
path_training <- "C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/training"
path_test <- "C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/test"
k <- 3
r <- 1
vocabulary <- GenerateVocabulary(path_training, n, swlang=lang)
vocabulary
View(GenerateVocabulary)
start.time <- Sys.time()
# Preparing parameters
n <- 50
lang <- "es"
#path_training <- "/home/algar11@alumno.upv.es/Descargas/pan-ap17-bigdata/training"		# Your training path
#path_test <- "/home/algar11@alumno.upv.es/Descargas/pan-ap17-bigdata/test"							# Your test path
path_training <- "C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/training"
path_test <- "C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/test"
k <- 3
r <- 1
# Auxiliar functions
# * GenerateVocabulary: Given a corpus (training set), obtains the n most frequent words
# * GenerateBoW: Given a corpus (training or test), and a vocabulary, obtains the bow representation
# GenerateVocabulary: Given a corpus (training set), obtains the n most frequent words
GenerateVocabulary <- function(path, n = 1000, lowcase = TRUE, punctuations = TRUE, numbers = TRUE, whitespaces = TRUE, swlang = "", swlist = "", verbose = TRUE, sex = "",pais = "")
{
setwd(path)
# Reading corpus list of files
files = list.files(pattern="*.xml")
tr = read.table("C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/training/truth.txt", sep=":")
tr = tr[,c(1,4,7)]
colnames(tr) <- c("id","sexo","pais")
tr$id <- as.character(tr$id)
# Reading files contents and concatenating into the corpus.raw variable
corpus.raw <- NULL
i <- 0
for (file in files)
{
# Para generar las palabras por sexo
if(sex!="")
{
file2 <- gsub(".xml","",file)
id_sex <- tr[which(tr$id == file2),2]
if(id_sex == sex)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
}
# Para generar las palabras por pais
if(pais!="")
{
file2 <- gsub(".xml","",file)
id_pais <- tr[which(tr$id == file2),3]
if(id_pais == pais)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
}
}
# Preprocessing the corpus
corpus.preprocessed <- corpus.raw
if (lowcase) {
if (verbose) print("Tolower...")
corpus.preprocessed <- tolower(corpus.preprocessed)
}
if (punctuations) {
if (verbose) print("Removing punctuations...")
corpus.preprocessed <- removePunctuation(corpus.preprocessed)
}
if (numbers) {
if (verbose) print("Removing numbers...")
corpus.preprocessed <- removeNumbers(corpus.preprocessed)
}
if (whitespaces) {
if (verbose) print("Stripping whitestpaces...")
corpus.preprocessed <- stripWhitespace(corpus.preprocessed)
}
if (swlang!="")	{
if (verbose) print(paste("Removing stopwords for language ", swlang , "..."))
corpus.preprocessed <- removeWords(corpus.preprocessed, stopwords(swlang))
}
if (swlist!="") {
if (verbose) print("Removing provided stopwords...")
corpus.preprocessed <- removeWords(corpus.preprocessed, swlist)
}
# Generating the vocabulary as the n most frequent terms
#if (verbose) print("Generating frequency terms")
#corpus.frequentterms <- freq_terms(corpus.preprocessed, n)
#if (verbose) plot(corpus.frequentterms)
#return (corpus.frequentterms)
return(corpus.preprocessed)
}
vocabulary_male <- GenerateVocabulary(path_training, n, swlang=lang, sex="male")
vocabulary_male
GenerateVocabulary <- function(path, n = 1000, lowcase = TRUE, punctuations = TRUE, numbers = TRUE, whitespaces = TRUE, swlang = "", swlist = "", verbose = TRUE, sex = "",pais = "")
{
setwd(path)
# Reading corpus list of files
files = list.files(pattern="*.xml")
tr = read.table("C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/training/truth.txt", sep=":")
tr = tr[,c(1,4,7)]
colnames(tr) <- c("id","sexo","pais")
tr$id <- as.character(tr$id)
# Reading files contents and concatenating into the corpus.raw variable
corpus.raw <- NULL
i <- 0
for (file in files)
{
# Para generar las palabras por sexo
if(sex!="")
{
file2 <- gsub(".xml","",file)
id_sex <- tr[which(tr$id == file2),2]
if(id_sex == sex)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
print(corpus.raw)
}
}
# Para generar las palabras por pais
if(pais!="")
{
file2 <- gsub(".xml","",file)
id_pais <- tr[which(tr$id == file2),3]
if(id_pais == pais)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
print(corpus.raw)
}
}
}
# Preprocessing the corpus
corpus.preprocessed <- corpus.raw
if (lowcase) {
if (verbose) print("Tolower...")
corpus.preprocessed <- tolower(corpus.preprocessed)
}
if (punctuations) {
if (verbose) print("Removing punctuations...")
corpus.preprocessed <- removePunctuation(corpus.preprocessed)
}
if (numbers) {
if (verbose) print("Removing numbers...")
corpus.preprocessed <- removeNumbers(corpus.preprocessed)
}
if (whitespaces) {
if (verbose) print("Stripping whitestpaces...")
corpus.preprocessed <- stripWhitespace(corpus.preprocessed)
}
if (swlang!="")	{
if (verbose) print(paste("Removing stopwords for language ", swlang , "..."))
corpus.preprocessed <- removeWords(corpus.preprocessed, stopwords(swlang))
}
if (swlist!="") {
if (verbose) print("Removing provided stopwords...")
corpus.preprocessed <- removeWords(corpus.preprocessed, swlist)
}
# Generating the vocabulary as the n most frequent terms
#if (verbose) print("Generating frequency terms")
#corpus.frequentterms <- freq_terms(corpus.preprocessed, n)
#if (verbose) plot(corpus.frequentterms)
#return (corpus.frequentterms)
return(corpus.preprocessed)
}
vocabulary_female <- GenerateVocabulary(path_training, n, swlang=lang, sex="female")
GenerateVocabulary <- function(path, n = 1000, lowcase = TRUE, punctuations = TRUE, numbers = TRUE, whitespaces = TRUE, swlang = "", swlist = "", verbose = TRUE, sex = "",pais = "")
{
setwd(path)
# Reading corpus list of files
files = list.files(pattern="*.xml")
tr = read.table("C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/training/truth.txt", sep=":")
tr = tr[,c(1,4,7)]
colnames(tr) <- c("id","sexo","pais")
tr$id <- as.character(tr$id)
# Reading files contents and concatenating into the corpus.raw variable
corpus.raw <- NULL
i <- 0
for (file in files)
{
# Para generar las palabras por sexo
if(sex!="")
{
file2 <- gsub(".xml","",file)
id_sex <- tr[which(tr$id == file2),2]
if(id_sex == sex)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
#corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", xmlValue))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
}
# Para generar las palabras por pais
if(pais!="")
{
file2 <- gsub(".xml","",file)
id_pais <- tr[which(tr$id == file2),3]
if(id_pais == pais)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
}
}
# Preprocessing the corpus
corpus.preprocessed <- corpus.raw
if (lowcase) {
if (verbose) print("Tolower...")
corpus.preprocessed <- tolower(corpus.preprocessed)
}
if (punctuations) {
if (verbose) print("Removing punctuations...")
corpus.preprocessed <- removePunctuation(corpus.preprocessed)
}
if (numbers) {
if (verbose) print("Removing numbers...")
corpus.preprocessed <- removeNumbers(corpus.preprocessed)
}
if (whitespaces) {
if (verbose) print("Stripping whitestpaces...")
corpus.preprocessed <- stripWhitespace(corpus.preprocessed)
}
if (swlang!="")	{
if (verbose) print(paste("Removing stopwords for language ", swlang , "..."))
corpus.preprocessed <- removeWords(corpus.preprocessed, stopwords(swlang))
}
if (swlist!="") {
if (verbose) print("Removing provided stopwords...")
corpus.preprocessed <- removeWords(corpus.preprocessed, swlist)
}
# Generating the vocabulary as the n most frequent terms
#if (verbose) print("Generating frequency terms")
#corpus.frequentterms <- freq_terms(corpus.preprocessed, n)
#if (verbose) plot(corpus.frequentterms)
#return (corpus.frequentterms)
return (corpus.preprocessed)
}
vocabulary_male <- GenerateVocabulary(path_training, n, swlang=lang, sex="male")
vocabulary_male
GenerateVocabulary <- function(path, n = 1000, lowcase = TRUE, punctuations = TRUE, numbers = TRUE, whitespaces = TRUE, swlang = "", swlist = "", verbose = TRUE, sex = "",pais = "")
{
setwd(path)
# Reading corpus list of files
files = list.files(pattern="*.xml")
tr = read.table("C:/Users/Iborra/Documents/DATOS VARIOS/MASTER BIG DATA/Asignaturas/TextMining en Social Media/pan-ap17-bigdata/training/truth.txt", sep=":")
tr = tr[,c(1,4,7)]
colnames(tr) <- c("id","sexo","pais")
tr$id <- as.character(tr$id)
# Reading files contents and concatenating into the corpus.raw variable
corpus.raw <- NULL
i <- 0
for (file in files)
{
# Para generar las palabras por sexo
if(sex!="")
{
file2 <- gsub(".xml","",file)
id_sex <- tr[which(tr$id == file2),2]
if(id_sex == sex)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
}
# Para generar las palabras por pais
if(pais!="")
{
file2 <- gsub(".xml","",file)
id_pais <- tr[which(tr$id == file2),3]
if(id_pais == pais)
{
xmlfile <- xmlTreeParse(file, useInternalNodes = TRUE)
corpus.raw <- c(corpus.raw, xpathApply(xmlfile, "//document", function(x) xmlValue(x)))
i <- i + 1
if (verbose) print(paste(i, " ", file))
}
}
}
# Preprocessing the corpus
corpus.preprocessed <- corpus.raw
if (lowcase) {
if (verbose) print("Tolower...")
corpus.preprocessed <- tolower(corpus.preprocessed)
}
if (punctuations) {
if (verbose) print("Removing punctuations...")
corpus.preprocessed <- removePunctuation(corpus.preprocessed)
}
if (numbers) {
if (verbose) print("Removing numbers...")
corpus.preprocessed <- removeNumbers(corpus.preprocessed)
}
if (whitespaces) {
if (verbose) print("Stripping whitestpaces...")
corpus.preprocessed <- stripWhitespace(corpus.preprocessed)
}
if (swlang!="")	{
if (verbose) print(paste("Removing stopwords for language ", swlang , "..."))
corpus.preprocessed <- removeWords(corpus.preprocessed, stopwords(swlang))
}
if (swlist!="") {
if (verbose) print("Removing provided stopwords...")
corpus.preprocessed <- removeWords(corpus.preprocessed, swlist)
}
# Generating the vocabulary as the n most frequent terms
#if (verbose) print("Generating frequency terms")
#corpus.frequentterms <- freq_terms(corpus.preprocessed, n)
#if (verbose) plot(corpus.frequentterms)
#return (corpus.frequentterms)
return (corpus.preprocessed)
}
vocabulary_male <- GenerateVocabulary(path_training, n, swlang=lang, sex="male")
vocabulary_male
